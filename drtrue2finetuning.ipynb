{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ9STxMRykg3BhLqidLuyt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-myeongji/dr.true-2/blob/ko/drtrue2finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puDzT8XjFN7p",
        "outputId": "331e2c53-cff5-424c-9fbc-dd469c5f7706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"\""
      ],
      "metadata": {
        "id": "zZsXmtDoFrkX"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aybksVZX5o0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e32891-f14e-4fb9-babd-37a0cfeb1a86"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\"prompt\":\"Company: BHFF insurance\\nProduct: allround insurance\\nAd:One stop shop for all your insurance needs!\\nSupported:\", \"completion\":\" yes\"}\n",
        "{\"prompt\":\"Company: Loft conversion specialists\\nProduct: -\\nAd:Straight teeth in weeks!\\nSupported:\", \"completion\":\" no\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hIvLzhtFzyK",
        "outputId": "75a9a271-f0c9-43e2-d5f5-27c2e34019d6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': 'Company: Loft conversion specialists\\nProduct: -\\nAd:Straight teeth in weeks!\\nSupported:',\n",
              " 'completion': ' no'}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f /content/drive/MyDrive/data.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uMaTRVYKMqU",
        "outputId": "3605f146-ffc8-4987-d40a-3a4a36ac9d87"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 5 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `/content/drive/MyDrive/data_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"/content/drive/MyDrive/data_prepared.jsonl\"\n",
            "\n",
            "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.51 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t /content/drive/MyDrive/data_prepared.jsonl -m davinci"
      ],
      "metadata": {
        "id": "fYZTNqaPNG87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8813fb39-fac8-447a-cbb4-7c26849a0e12"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found potentially duplicated files with name 'data_prepared.jsonl', purpose 'fine-tune' and size 568 bytes\n",
            "file-lZVhCBVwh1oAcW2pKDbBdPGO\n",
            "file-hBnqdE891oVIsYbWqXG16Dv7\n",
            "file-g9stDUzLn9NhVvg18VawRsN6\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: \n",
            "Upload progress: 100% 568/568 [00:00<00:00, 623kit/s]\n",
            "Uploaded file from /content/drive/MyDrive/data_prepared.jsonl: file-FDh3CYiJmH1TeKnhmQgTraiY\n",
            "Created fine-tune: ft-O5TmFrxLM8DcTOPspU87kmun\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-05-17 05:04:37] Created fine-tune: ft-O5TmFrxLM8DcTOPspU87kmun\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-O5TmFrxLM8DcTOPspU87kmun\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"\"\n",
        "\n",
        "engines = openai.Engine.list()\n",
        "for engine in engines['data']:\n",
        "    print(engine['id'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiD5DLjCGeNZ",
        "outputId": "9191b3f1-58f0-46a8-d50f-58993061de11"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whisper-1\n",
            "babbage\n",
            "davinci\n",
            "text-davinci-edit-001\n",
            "babbage-code-search-code\n",
            "text-similarity-babbage-001\n",
            "code-davinci-edit-001\n",
            "text-davinci-001\n",
            "ada\n",
            "text-davinci-003\n",
            "babbage-code-search-text\n",
            "babbage-similarity\n",
            "code-search-babbage-text-001\n",
            "gpt-3.5-turbo-0301\n",
            "text-curie-001\n",
            "code-search-babbage-code-001\n",
            "text-ada-001\n",
            "text-embedding-ada-002\n",
            "text-similarity-ada-001\n",
            "curie-instruct-beta\n",
            "gpt-3.5-turbo\n",
            "ada-code-search-code\n",
            "ada-similarity\n",
            "code-search-ada-text-001\n",
            "text-search-ada-query-001\n",
            "davinci-search-document\n",
            "ada-code-search-text\n",
            "text-search-ada-doc-001\n",
            "davinci-instruct-beta\n",
            "text-similarity-curie-001\n",
            "code-search-ada-code-001\n",
            "ada-search-query\n",
            "text-search-davinci-query-001\n",
            "curie-search-query\n",
            "davinci-search-query\n",
            "babbage-search-document\n",
            "ada-search-document\n",
            "text-search-curie-query-001\n",
            "text-search-babbage-doc-001\n",
            "curie-search-document\n",
            "text-search-curie-doc-001\n",
            "babbage-search-query\n",
            "text-babbage-001\n",
            "text-search-davinci-doc-001\n",
            "text-search-babbage-query-001\n",
            "curie-similarity\n",
            "curie\n",
            "text-similarity-davinci-001\n",
            "text-davinci-002\n",
            "davinci-similarity\n"
          ]
        }
      ]
    }
  ]
}